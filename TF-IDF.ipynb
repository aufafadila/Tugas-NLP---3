{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize #import word_tokenize for tokenizing text into words \n",
    "from nltk.tokenize import sent_tokenize #import sent_tokenize for tokenizing paragraph into sentences\n",
    "from nltk.stem.porter import PorterStemmer #import Porter Stemmer Algorithm \n",
    "from nltk.stem import WordNetLemmatizer #import WordNet lemmatizer \n",
    "from nltk.corpus import stopwords #import stopwords\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory #import Indonesian Stemmer\n",
    "import re, string\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import sys\n",
    "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input file\n",
    "def input_text(file):\n",
    "    f = open(file,'r')\n",
    "    isifile = f.readlines()\n",
    "    isifile = ''.join(isifile)\n",
    "    return isifile\n",
    "\n",
    "# sentence tokenization\n",
    "def sentence_tokenization(s):\n",
    "    sentences_list = sent_tokenize(s)\n",
    "    sentences_list = \" \".join(sentences_list)\n",
    "    return sentences_list\n",
    "\n",
    "# stopword remover\n",
    "def stopword_re(s):\n",
    "    factory = StopWordRemoverFactory()\n",
    "    data = factory.get_stop_words()\n",
    "    stopword = factory.create_stop_word_remover()\n",
    "    text_stopword = stopword.remove(s)\n",
    "    return text_stopword\n",
    "    \n",
    "    for w in word_tokens: \n",
    "        if w not in stop_words: \n",
    "            filtered_sentence.append(w)\n",
    "    return filtered_sentence\n",
    "\n",
    "#remove number\n",
    "def removeNumber(str):\n",
    "    new_string =  re.sub(r\"[0-9]\", \"\", str)\n",
    "    return new_string\n",
    "\n",
    "#remove punctuation\n",
    "def removePunc(s):  # From S.Lott's solution\n",
    "    for c in string.punctuation:\n",
    "        s = s.replace(c,\" \")\n",
    "    return s\n",
    "\n",
    "# Stemming\n",
    "def stemmingIndo(str):\n",
    "    factory = StemmerFactory()\n",
    "    stemmer = factory.create_stemmer()\n",
    "    return stemmer.stem(str)\n",
    "\n",
    "# word tokenization\n",
    "def word_tokenization(s):\n",
    "    token2 = word_tokenize(s)\n",
    "    return token2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          kata    tf-idf\n",
      "60    konsumen  0.055794\n",
      "21       batal  0.042918\n",
      "58      kemudi  0.038627\n",
      "70      mediko  0.034335\n",
      "31      cancel  0.034335\n",
      "46        jadi  0.030043\n",
      "79       nilai  0.025751\n",
      "84       pesan  0.025751\n",
      "41        grab  0.025751\n",
      "94      sering  0.025751\n",
      "0          ada  0.025751\n",
      "49       jelas  0.021459\n",
      "73       minta  0.021459\n",
      "56        kata  0.021459\n",
      "29      blokir  0.021459\n",
      "12     apabila  0.017167\n",
      "91       sebut  0.012876\n",
      "7         akun  0.012876\n",
      "78       nanti  0.012876\n",
      "8         alas  0.012876\n",
      "45   indonesia  0.012876\n",
      "75       mitra  0.012876\n",
      "3          aju  0.008584\n",
      "47     jakarta  0.008584\n",
      "51       kalau  0.008584\n",
      "4         akan  0.008584\n",
      "109      tutur  0.008584\n",
      "1         adil  0.008584\n",
      "98         tak  0.008584\n",
      "20     banding  0.008584\n",
      "..         ...       ...\n",
      "11         apa  0.004292\n",
      "10      anggap  0.004292\n",
      "9         aneh  0.004292\n",
      "6          aku  0.004292\n",
      "5        akhir  0.004292\n",
      "2         agar  0.004292\n",
      "32     carlton  0.004292\n",
      "34         cnn  0.004292\n",
      "67     masalah  0.004292\n",
      "35       dapat  0.004292\n",
      "66   marketing  0.004292\n",
      "64        main  0.004292\n",
      "63      lanjut  0.004292\n",
      "62        lama  0.004292\n",
      "59     kendati  0.004292\n",
      "55     kasihan  0.004292\n",
      "54         kan  0.004292\n",
      "53        kami  0.004292\n",
      "52        kali  0.004292\n",
      "50         jnp  0.004292\n",
      "48      jarang  0.004292\n",
      "44   ilustrasi  0.004292\n",
      "43          ia  0.004292\n",
      "42       hotel  0.004292\n",
      "40         evn  0.004292\n",
      "39         dua  0.004292\n",
      "38      driver  0.004292\n",
      "37    director  0.004292\n",
      "36          di  0.004292\n",
      "113      utama  0.004292\n",
      "\n",
      "[114 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    teks = input_text('artikelTFIDF.txt')\n",
    "    teks_token = sentence_tokenization(teks)\n",
    "    teks_remove = removePunc(teks_token)\n",
    "    teks_reNumber = removeNumber(teks_remove)\n",
    "    teks_stopword = stopword_re(teks_reNumber)\n",
    "    teks_stemming = stemmingIndo(teks_stopword)\n",
    "    kata = word_tokenization(teks_stemming)\n",
    "    \n",
    "    vectorizer = TfidfVectorizer(min_df = 1)\n",
    "    X = vectorizer.fit_transform(kata)\n",
    "    idf = vectorizer.idf_\n",
    "    unik = vectorizer.get_feature_names()\n",
    "    tfidf = np.asarray(X.mean(axis=0)).ravel().tolist()\n",
    "    weights_df = pd.DataFrame({'kata': unik, 'tf-idf': tfidf})\n",
    "    print(weights_df.sort_values(by='tf-idf', ascending=False))\n",
    "    \n",
    "if __name__== \"__main__\":\n",
    "    main()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
